{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-hBsyvXhyXj_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amA_9w3AzMMR",
    "outputId": "1ecce7f6-f95f-4ab6-c126-cd4e31e1d30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 249 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "train_path = (r'C:\\Users\\MARK JOSEPH\\CNN\\Covid19-dataset\\train')\n",
    "train_dataset = train.flow_from_directory(train_path, target_size = (224, 224), batch_size = 32, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiRb7unk4ZJl",
    "outputId": "e62e9d95-d29e-4b9b-ecaa-5824648bd989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test = ImageDataGenerator(rescale=1./255)\n",
    "test_path = (r'C:\\Users\\MARK JOSEPH\\CNN\\Covid19-dataset\\test')\n",
    "test_dataset = train.flow_from_directory(test_path,target_size = (224, 224), batch_size = 32, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dVQP21swKyFj"
   },
   "outputs": [],
   "source": [
    "from keras.backend import categorical_crossentropy\n",
    "model = Sequential()\n",
    "\n",
    "#Conv. Layer 1\n",
    "model.add(Conv2D(32,\n",
    "                 kernel_size=(3,3), #Standard\n",
    "                 activation='relu',\n",
    "                 input_shape=(224,224,3)))\n",
    "\n",
    "#Conv. Layer 2\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Conv. Layer 3\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "#Conv. Layer 4\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Conv. Layer 5\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNYVecWHeVgr",
    "outputId": "06402dfd-294b-4438-a010-fcf70673a4a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 220, 220, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 110, 110, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 110, 110, 64)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 108, 108, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 54, 54, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                5537856   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,668,227\n",
      "Trainable params: 5,668,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWNhXuxceb_a",
    "outputId": "86b2dc17-f38d-4fcf-d6f7-f6c9e0664580"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_MAIN\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 37s 5s/step - loss: 1.2535 - accuracy: 0.4147 - val_loss: 1.0914 - val_accuracy: 0.3906\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 30s 4s/step - loss: 1.0090 - accuracy: 0.5069 - val_loss: 0.9756 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.8572 - accuracy: 0.6083 - val_loss: 0.8176 - val_accuracy: 0.6406\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.6186 - accuracy: 0.7419 - val_loss: 0.5607 - val_accuracy: 0.7344\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 32s 4s/step - loss: 0.5063 - accuracy: 0.7788 - val_loss: 0.6326 - val_accuracy: 0.7188\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.5223 - accuracy: 0.8111 - val_loss: 0.7309 - val_accuracy: 0.6250\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.5069 - accuracy: 0.7696 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.5003 - accuracy: 0.8249 - val_loss: 0.5883 - val_accuracy: 0.6562\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.3960 - accuracy: 0.8249 - val_loss: 0.5736 - val_accuracy: 0.7188\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.5386 - accuracy: 0.7696 - val_loss: 0.5640 - val_accuracy: 0.7812\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.5151 - val_accuracy: 0.7188\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.4058 - accuracy: 0.8479 - val_loss: 0.6412 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.3610 - accuracy: 0.8525 - val_loss: 0.5197 - val_accuracy: 0.8125\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.3962 - accuracy: 0.8571 - val_loss: 0.4779 - val_accuracy: 0.7344\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.5265 - accuracy: 0.7788 - val_loss: 0.7157 - val_accuracy: 0.7969\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.5274 - accuracy: 0.7742 - val_loss: 0.5163 - val_accuracy: 0.8281\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.4258 - accuracy: 0.8157 - val_loss: 0.4511 - val_accuracy: 0.7969\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.3991 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7812\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.3157 - accuracy: 0.8571 - val_loss: 0.6514 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.4520 - accuracy: 0.8157 - val_loss: 0.5049 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_dataset, steps_per_epoch=7, epochs = 20, validation_data = test_dataset,validation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqevIJCM0J7e",
    "outputId": "9d574c6c-1694-4864-dabe-72807a749ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 13s 2s/step - loss: 0.2751 - accuracy: 0.8956\n",
      "Test score: 0.27509957551956177\n",
      "Test accuracy: 0.8955823183059692\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(train_dataset)\n",
    "print('Test score:', result[0])\n",
    "print('Test accuracy:', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_dir = (r'C:/Users/MARK JOSEPH/CNN/Covid19-dataset/')\n",
    "def loadImages(path, folder):\n",
    "    data_files = sorted([os.path.join(path, folder, file)\n",
    "                        for file in os.listdir(path + folder + '/')\n",
    "                        if (file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.png') or file.endswith('.webp'))])\n",
    "    return data_files\n",
    "\n",
    "validation_dataset = loadImages(path_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uc8QKdjoDMkK"
   },
   "outputs": [],
   "source": [
    "valid = validation_dataset\n",
    "output = []\n",
    "images = []\n",
    "\n",
    "for x in valid:\n",
    "    img = cv2.imread(x)\n",
    "    img = img[:, :, :3]\n",
    "    images.append(img)\n",
    "\n",
    "    width = 224\n",
    "    height = 224\n",
    "    dim = (width, height)\n",
    "\n",
    "    resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "    output.append(resized)\n",
    "output = np.array(output)\n",
    "output = output/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test = ImageDataGenerator(rescale=1./255)\n",
    "test_path = (r'C:\\Users\\MARK JOSEPH\\CNN\\Covid19-dataset\\test')\n",
    "test_dataset = train.flow_from_directory(test_path, \n",
    "                                         target_size = (224, 224), \n",
    "                                         batch_size = 32, \n",
    "                                         class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUfl58h1Dj46",
    "outputId": "74859c6d-f261-4650-a685-21771e7c7b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 285ms/step\n",
      "[1 1 0 2 2 2 0 0 2 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(output)\n",
    "predict = np.argmax(y_pred, axis=1)\n",
    "print(predict)\n",
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23ae2a1fd88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(y_pred.reshape(10,3), interpolation = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U70YF6CVHHab"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
